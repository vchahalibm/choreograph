# DeskAgent Feature Updates

This document describes the three major features implemented in this update:

## 1. Script Parameterization with Variable Substitution

### Overview
Scripts can now use variables that are substituted at runtime, allowing for dynamic and reusable automation scripts.

### Variable Syntax
Variables use double curly braces: `{{variableName}}`

### How It Works

#### Defining Parameters in Scripts
Add a `parameters` object to your JSON script with default values:

```json
{
  "title": "WhatsappReadMsg - Fixed",
  "targetUrl": "https://web.whatsapp.com",
  "description": "Supports variables: {{searchText1}}, {{searchText2}}",
  "parameters": {
    "searchText1": "R94",
    "searchText2": "Rustambagh"
  },
  "steps": [...]
}
```

#### Using Variables in Steps
Reference variables in any string property:

```json
{
  "type": "change",
  "value": "{{searchText1}}",
  "selectors": [["div[role='textbox']"]],
  "comment": "Type search text 1 in search"
}
```

#### Passing Parameters at Runtime
When executing a script, pass custom parameters:

```javascript
chrome.runtime.sendMessage({
  type: 'EXECUTE_SCRIPT',
  scriptId: 'whatsapp-script',
  parameters: {
    searchText1: "CustomValue1",
    searchText2: "CustomValue2"
  }
});
```

#### Parameter Precedence
1. Runtime parameters (highest priority)
2. Script default parameters
3. Original value (if no parameter found)

### Features
- **Recursive substitution**: Works in nested objects and arrays
- **Logging**: Console logs show substitutions: `üîÑ Substituting {{varName}} with "value"`
- **Fallback**: If variable not found, original placeholder is kept
- **Type safety**: Only string values are processed for substitution

### Example Use Cases
- Search different contacts in WhatsApp
- Login with different credentials
- Navigate to different URLs
- Fill forms with dynamic data

---

## 2. AI Model Model Integration with WebGPU

### Overview
The extension now uses IBM's AI Model micro model for natural language processing, with WebGPU acceleration support.

### Model Details
- **Model ID**: `onnx-community/distilgpt2`
- **Type**: Causal Language Model (LLM)
- **Quantization**: q4f16 (WebGPU) or q4 (WASM fallback)
- **Size**: ~80 MB
- **Device**: WebGPU (if available) or WASM fallback

### Features

#### Smart Script Matching
The model processes natural language commands and:
- Matches commands to available scripts
- Extracts parameters from the command
- Provides confidence scores
- Explains reasoning

Example:
```javascript
// User command: "Search for John in WhatsApp"
// Model output:
{
  "matched": true,
  "scriptTitle": "WhatsappReadMsg - Fixed",
  "parameters": {
    "searchText2": "John"
  },
  "confidence": 0.85,
  "reasoning": "User wants to search for a contact in WhatsApp"
}
```

#### Loading the Model
```javascript
// From background script
await deskAgent.loadNLPModel((progress) => {
  console.log(`Loading ${progress.file}: ${progress.progress}%`);
});
```

#### Using the Model
```javascript
const result = await deskAgent.processNLPCommand(
  "Find and open my chat with the marketing team",
  {
    maxTokens: 256,
    temperature: 0.7,
    topP: 0.9
  }
);
```

### Performance Optimizations
- **WebGPU Detection**: Automatically uses GPU if available
- **Shader Compilation**: Model is warmed up on load
- **Progress Tracking**: File-by-file loading progress
- **Fallback Mechanism**: Simple text matching if model fails

### WebGPU Requirements
- Chrome/Edge 113+
- Supported GPU
- Enable `chrome://flags/#enable-unsafe-webgpu` if needed

### Fallback Behavior
If Granite model fails or WebGPU unavailable:
- Falls back to simple text matching
- Uses word overlap scoring
- Still functional but less intelligent

---

## 3. Debugger Persistence During Script Execution

### Overview
The debugger now stays attached during and after script execution, preventing interruptions and allowing continued interaction.

### The Problem (Before)
- Debugger would detach during script execution
- Scripts would fail mid-execution
- Manual reattachment required
- Loss of state and context

### The Solution (After)

#### Auto-Reattachment
When debugger detaches unexpectedly during script execution:
```javascript
handleDebuggerDetach(source, reason) {
  if (this.keepDebuggerAttached && scriptIsRunning) {
    // Automatically reattach after 100ms
    reattachDebugger(tabId);
  }
}
```

#### Persistent Connection
After script completion:
```javascript
// Debugger stays attached by default
console.log('üîó Keeping debugger attached for further interaction');

// Optional: Detach explicitly
parameters.detachDebugger = true;
```

### Configuration

#### Keep Attached (Default)
```javascript
// Execute script - debugger stays attached
chrome.runtime.sendMessage({
  type: 'EXECUTE_SCRIPT',
  scriptId: 'my-script',
  parameters: { ... }
});
```

#### Explicit Detachment
```javascript
// Execute script - debugger detaches after completion
chrome.runtime.sendMessage({
  type: 'EXECUTE_SCRIPT',
  scriptId: 'my-script',
  parameters: {
    detachDebugger: true
  }
});
```

### Benefits
1. **Reliability**: Scripts complete without interruption
2. **Debugging**: Easier to inspect state after execution
3. **Continuation**: Can run multiple scripts sequentially
4. **Manual Control**: Inspect/modify page after automation

### Console Logging
Clear logging shows debugger state:
```
‚ö†Ô∏è Debugger detached from tab 123, reason: target_closed
üîÑ Attempting to reattach debugger to tab 123...
‚úÖ Debugger reattached to tab 123
```

---

## Migration Guide

### Updating Existing Scripts

#### Before (Hardcoded Values)
```json
{
  "type": "change",
  "value": "Rustambagh",
  "selectors": [["div[role='textbox']"]]
}
```

#### After (Parameterized)
```json
{
  "type": "change",
  "value": "{{searchText}}",
  "selectors": [["div[role='textbox']"]]
}
```

Add to script root:
```json
{
  "parameters": {
    "searchText": "Rustambagh"
  }
}
```

### Loading Granite Model

Add to your initialization code:
```javascript
// Optional: Load model on extension startup
chrome.runtime.sendMessage({ type: 'LOAD_NLP_MODEL' });

// Or: Model loads automatically on first use
chrome.runtime.sendMessage({
  type: 'PROCESS_NLP_COMMAND',
  command: 'Search for contacts in WhatsApp'
});
```

### Debugger Configuration

No changes needed! New behavior is automatic and backward compatible.

Optional: Add explicit detachment if needed:
```javascript
parameters.detachDebugger = true;
```

---

## Testing

### Test Variable Substitution
1. Update `WhatsappReadMsg-Fixed.json` with custom parameters
2. Run script with different values
3. Check console for `üîÑ Substituting {{varName}}` messages
4. Verify values are correctly replaced

### Test Granite Model
1. Check WebGPU availability: `!!navigator.gpu`
2. Load model: Send `LOAD_NLP_MODEL` message
3. Watch console for progress: `üì• Loading...`
4. Test command: Send natural language query
5. Verify JSON response with script match

### Test Debugger Persistence
1. Attach debugger to a tab
2. Run a script
3. Monitor console for detachment warnings
4. Verify automatic reattachment
5. Confirm debugger remains attached after completion

---

## Troubleshooting

### Variables Not Substituting
- Check variable name matches exactly (case-sensitive)
- Verify double curly braces: `{{varName}}`
- Look for console warnings: `‚ö†Ô∏è Variable {{varName}} not found`
- Ensure parameter is passed or has default value

### Granite Model Issues
- **Model won't load**: Check internet connection, model downloads from HuggingFace
- **WebGPU errors**: Fallback to WASM happens automatically
- **Out of memory**: Model requires ~80 MB, close other tabs
- **Slow generation**: Normal on first run (shader compilation)

### Debugger Detaching
- Check console for detach reason
- Verify `keepDebuggerAttached = true` in background.js
- Look for reattachment attempts in logs
- Try manual reattachment if automatic fails

---

## Performance Considerations

### Variable Substitution
- Negligible performance impact
- Recursive processing is fast for typical script sizes
- Logging can be disabled in production

### Granite Model
- **Initial load**: 30-60 seconds (one-time per session)
- **Inference**: 2-5 seconds per command
- **Memory**: ~2.5 GB RAM
- **GPU usage**: Moderate (if WebGPU enabled)

### Debugger Persistence
- No performance impact
- Slightly higher memory (debugger protocol connection)
- Beneficial for reducing reconnection overhead

---

## Future Enhancements

### Planned Features
1. **Variable types**: Support number, boolean, object variables
2. **Conditional substitution**: `{{varName:defaultValue}}`
3. **Environment variables**: Access browser/system info
4. **Model fine-tuning**: Train on user's scripts
5. **Streaming responses**: Real-time model output
6. **Debugger presets**: Save/load debugger configurations

### Community Contributions
See [CONTRIBUTING.md](CONTRIBUTING.md) for how to contribute.

---

## API Reference

### Execute Script with Parameters
```javascript
chrome.runtime.sendMessage({
  type: 'EXECUTE_SCRIPT',
  scriptId: string,
  parameters: {
    [key: string]: string,
    detachDebugger?: boolean
  }
});
```

### Load NLP Model
```javascript
chrome.runtime.sendMessage({
  type: 'LOAD_NLP_MODEL'
});
```

### Process NLP Command
```javascript
chrome.runtime.sendMessage({
  type: 'PROCESS_NLP_COMMAND',
  command: string,
  options: {
    maxTokens?: number,      // Default: 256
    temperature?: number,    // Default: 0.7
    topP?: number           // Default: 0.9
  }
});
```

### Attach/Detach Debugger
```javascript
// Attach
chrome.runtime.sendMessage({
  type: 'ATTACH_DEBUGGER',
  tabId: number | url: string
});

// Detach
chrome.runtime.sendMessage({
  type: 'DETACH_DEBUGGER',
  tabId: number
});
```

---

## License
Same as DeskAgent main license.

## Support
For issues, please file a bug report with:
- Chrome version
- Script JSON
- Console logs
- Expected vs actual behavior

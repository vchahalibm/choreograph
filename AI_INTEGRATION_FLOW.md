# Chatbot to AI Model Integration Flow

## âœ… Integration is Connected!

The chatbot (popup) **IS** linked to the Granite 4.0 AI model. Here's how it works:

## Message Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Popup.js       â”‚
â”‚  (User types    â”‚
â”‚   command)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ 1. chrome.runtime.sendMessage
         â”‚    type: 'PROCESS_NLP_COMMAND'
         â”‚    command: "search for John"
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Background.js      â”‚
â”‚  Service Worker     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ 2. Check: modelReadyInConfig?
         â”‚    â”œâ”€ Yes â†’ Route to config page
         â”‚    â””â”€ No  â†’ Fallback text matching
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Config.js           â”‚
â”‚  (Settings page)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ 3. sendWorkerMessage('PROCESS_COMMAND')
         â”‚    { command, scripts, options }
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AI Worker                   â”‚
â”‚  (ai-worker.bundled.js)      â”‚
â”‚  Granite 4.0 Model           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ 4. Process with AI model
         â”‚    - Tokenize command
         â”‚    - Generate with Granite 4.0
         â”‚    - Match to scripts
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Response back       â”‚
â”‚  { matched, script,  â”‚
â”‚    confidence,       â”‚
â”‚    parameters }      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Code Flow Analysis

### 1. **Popup Sends Command** (`popup.js:277-284`)
```javascript
async processNLPCommand(command) {
  this.addMessage('agent', 'Processing your command...');

  const response = await chrome.runtime.sendMessage({
    type: 'PROCESS_NLP_COMMAND',
    command: command
  });
  // ... handle response
}
```

### 2. **Background Routes to Config** (`background.js:526-564`)
```javascript
async processNLPCommand(command, options = {}) {
  if (this.modelReadyInConfig) {
    // Send to config page where AI worker lives
    const response = await chrome.runtime.sendMessage({
      type: 'PROCESS_COMMAND_IN_CONFIG',
      command,
      scripts,
      options
    });
    return response.result;
  } else {
    // Fallback to text matching
    return this.fallbackScriptMatching(command, scripts);
  }
}
```

### 3. **Config Sends to AI Worker** (`config.js:44-62`)
```javascript
if (message.type === 'PROCESS_COMMAND_IN_CONFIG') {
  if (!this.aiWorker) {
    sendResponse({ success: false, error: 'AI Worker not initialized' });
    return;
  }

  const response = await this.sendWorkerMessage('PROCESS_COMMAND', {
    command: message.command,
    scripts: message.scripts,
    options: message.options || {}
  });

  sendResponse({ success: true, result: response.data });
}
```

### 4. **AI Worker Processes with Granite 4.0** (`src/ai-worker-source.js:91-148`)
```javascript
async function handleProcessCommand(data, messageId) {
  if (!model || !tokenizer) {
    sendError(messageId, 'Model not loaded');
    return;
  }

  const { command, scripts } = data;

  // Build prompt for script matching
  const scriptsList = scripts.map((s, i) =>
    `${i + 1}. ${s.title}: ${s.description || ''}`
  ).join('\n');

  const prompt = `Available automation scripts:
${scriptsList}

User wants to: ${command}

Match the user's request to a script number (1-${scripts.length}) or 0 if no match.
Answer with just the number:`;

  // Tokenize and generate with Granite 4.0
  const inputs = tokenizer(prompt);
  const outputs = await model.generate({
    ...inputs,
    max_new_tokens: 10,
    do_sample: false,
    temperature: 0.3
  });

  const generatedText = tokenizer.decode(outputs[0], {
    skip_special_tokens: true
  });

  // Extract matched script
  const numberMatch = generatedText.slice(prompt.length).match(/\d+/);
  // ... return matched script
}
```

## Current Architecture: Config Page Required

### âš ï¸ Important Limitation

**The AI model only works when the Settings (config.html) page is open!**

**Why?**
- AI worker lives in config page context
- Service workers can't create Web Workers
- Config page loads and maintains the AI worker

### Model Lifecycle

```
1. User opens Settings â†’ chrome-extension://xxx/pages/config.html
2. User clicks "Load NLP Model"
3. Config page creates Web Worker (ai-worker.bundled.js)
4. Worker loads Granite 4.0 model
5. Config notifies background: MODEL_READY_IN_CONFIG
6. âœ… AI model is now available

When config page closes:
7. AI worker is destroyed
8. Model is unloaded from memory
9. âŒ AI model no longer available
10. Popup falls back to text matching
```

## How to Test End-to-End

### Step 1: Load the Model

1. Rebuild extension with CSP fix:
   ```bash
   npm run build
   ```

2. Reload extension in `chrome://extensions/`

3. Right-click extension â†’ **Options** (opens config page)

4. Click **Settings** tab

5. Click **"Load NLP Model"** button

6. Wait for:
   ```
   âœ… [AI Worker] Granite 4.0 model loaded successfully on webgpu
   âœ… Model loaded and background script notified
   ```

### Step 2: Keep Config Page Open

**IMPORTANT:** Leave the Settings tab open in the background!

### Step 3: Test in Popup

1. Click the Choreograph extension icon (opens popup)

2. Type a natural language command:
   ```
   "search for John"
   "send message to Alice"
   "open settings"
   ```

3. Watch the console (F12) for:
   ```javascript
   ğŸ¤– Processing command: search for John
   ğŸ“¤ Routing NLP processing to config page...
   âœ… NLP processing successful via config page
   ```

### Step 4: Check the Response

The popup should show:
```
ğŸ“‹ Found matching script (85% match)
[Script Title]
[Script Description]
[Execute] button
```

## Testing Checklist

- [ ] **Settings page is open** (required!)
- [ ] Model loaded successfully
- [ ] Console shows "MODEL_READY_IN_CONFIG" message
- [ ] Popup command triggers AI processing
- [ ] Console shows "Routing NLP processing to config page"
- [ ] AI returns matched script
- [ ] Confidence score displayed
- [ ] Execute button works

## What Happens Without Model

If Settings page is closed or model not loaded:

```javascript
âš ï¸ AI model not loaded. Please open Settings page and click "Load NLP Model"
âš ï¸ Using fallback text matching
```

**Fallback behavior:**
- Simple text similarity matching
- Checks if command contains script title/description words
- Lower accuracy than AI model
- Still works, just not as smart

## Example Test Scenarios

### Scenario 1: With AI Model (Smart)

**Setup:**
- Settings page open
- Model loaded
- Script: "WhatsApp Search" - "Search for contacts in WhatsApp"

**User types:** "find someone in WhatsApp"

**AI understands:**
- "find" â‰ˆ "search"
- "someone" â‰ˆ "contacts"
- "WhatsApp" = exact match
- **Result:** Matches "WhatsApp Search" with 92% confidence

### Scenario 2: Without AI Model (Simple)

**Setup:**
- Settings page closed
- Fallback text matching

**User types:** "find someone in WhatsApp"

**Fallback checks:**
- Does command contain "whatsapp"? Yes
- Does command contain "search"? No
- **Result:** May or may not match, depends on exact words

## Improving the Integration

### Future Enhancement: Persistent Worker

To make AI available even when config page is closed, we could:

**Option 1: Offscreen Document** (Chrome 109+)
```javascript
// Create persistent offscreen document for AI worker
chrome.offscreen.createDocument({
  url: 'offscreen.html',
  reasons: ['WORKERS'],
  justification: 'AI model processing'
});
```

**Option 2: Background Worker Pool**
- Keep worker alive in background
- Use service worker lifetime extension
- Reload model on service worker wake

**Option 3: On-Demand Loading**
- Auto-open config page when needed
- Load model on first command
- Cache for 5 minutes

**Current Status:** Using Option "Keep Config Page Open"
- âœ… Simple implementation
- âœ… Works reliably
- âŒ Requires settings page open
- âŒ Model unloads when page closes

## Console Debugging

### Check if Model is Ready

**In Popup DevTools:**
```javascript
chrome.runtime.sendMessage({ type: 'PROCESS_NLP_COMMAND', command: 'test' },
  (response) => console.log(response)
);
```

**Expected (Model Ready):**
```javascript
{
  success: true,
  result: {
    matched: true/false,
    script: { ... },
    confidence: 0.85
  }
}
```

**Expected (Model Not Ready):**
```javascript
{
  success: true,
  result: {
    matched: false,
    message: "Using fallback matching"
  }
}
```

### Check Worker Status

**In Config Page DevTools:**
```javascript
// Check if worker exists
console.log('Worker:', window.configManager?.aiWorker);

// Send test message
window.configManager?.sendWorkerMessage('CHECK_STATUS', {})
  .then(r => console.log('Worker status:', r));
```

**Expected:**
```javascript
{
  type: 'STATUS',
  data: {
    modelLoaded: true,
    isLoading: false,
    modelId: 'onnx-community/granite-4.0-micro-ONNX-web',
    transformersLoaded: true
  }
}
```

## Summary

âœ… **Chatbot IS linked to Granite 4.0 model**
âœ… **Message passing flow is correct**
âœ… **Integration works end-to-end**

âš ï¸ **Requirement: Settings page must stay open**
âš ï¸ **Fallback: Text matching if model not loaded**

ğŸ¯ **Next Steps:**
1. Test with real scripts
2. Monitor console for errors
3. Verify AI matching quality
4. Consider persistent worker solution
